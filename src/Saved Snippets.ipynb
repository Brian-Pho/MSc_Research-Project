{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved Snippets\n",
    "This script holds random snippets of code that I may need again, but are cluttering the main scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom PLSRW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import pinv2\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _center_scale_xy(X, Y, scale=True):\n",
    "    \"\"\" Center X, Y and scale if the scale parameter==True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        X, Y, x_mean, y_mean, x_std, y_std\n",
    "    \"\"\"\n",
    "    # center\n",
    "    x_mean = X.mean(axis=0)\n",
    "    X -= x_mean\n",
    "    y_mean = Y.mean(axis=0)\n",
    "    Y -= y_mean\n",
    "    # scale\n",
    "    if scale:\n",
    "        x_std = X.std(axis=0, ddof=1)\n",
    "        x_std[x_std == 0.0] = 1.0\n",
    "        X /= x_std\n",
    "        y_std = Y.std(axis=0, ddof=1)\n",
    "        y_std[y_std == 0.0] = 1.0\n",
    "        Y /= y_std\n",
    "    else:\n",
    "        x_std = np.ones(X.shape[1])\n",
    "        y_std = np.ones(Y.shape[1])\n",
    "    return X, Y, x_mean, y_mean, x_std, y_std\n",
    "\n",
    "\n",
    "class PLSRW():\n",
    "    \n",
    "    def __init__(self, n_components=2, scale=True, reg=0.01):\n",
    "        self.n_components=n_components\n",
    "        self.scale = scale\n",
    "        self.reg = reg\n",
    "    \n",
    "    def _calc_dist(self, X, Y):\n",
    "        dist = []\n",
    "        \n",
    "        for feature in range(X.shape[1]):\n",
    "            feature_dist = np.linalg.norm(Y - X[:, feature])\n",
    "            dist.append(feature_dist)\n",
    "        \n",
    "        return np.array(dist)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        Y = Y.astype('float64')\n",
    "        if Y.ndim == 1:\n",
    "            Y = Y.reshape(-1, 1)\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        q = Y.shape[1]\n",
    "        \n",
    "        n_components = self.n_components\n",
    "        reg = self.reg\n",
    "        eps = np.finfo(X.dtype).eps\n",
    "        Y_eps = np.finfo(Y.dtype).eps\n",
    "        \n",
    "        self.x_weights_ = np.zeros((p, n_components))  # U\n",
    "        self._x_scores = np.zeros((n, n_components))  # Xi\n",
    "        self.x_loadings_ = np.zeros((p, n_components))  # Gamma\n",
    "        self.y_loadings_ = np.zeros((q, n_components))  # Delta\n",
    "        \n",
    "        # Scale (in place)\n",
    "        Xk, Yk, self._x_mean, self._y_mean, self._x_std, self._y_std = (\n",
    "            _center_scale_xy(X, Y, self.scale))\n",
    "        Yk_mask = np.all(np.abs(Yk) < 10 * Y_eps, axis=0)\n",
    "        Yk[:, Yk_mask] = 0.0\n",
    "        \n",
    "        for k in range(n_components):\n",
    "            # Compute the regularization matrix\n",
    "            d = self._calc_dist(Xk, Yk)\n",
    "            D = np.diag(d)\n",
    "            print(reg * (D.T @ D))\n",
    "            print((Xk.T @ Xk))\n",
    "            \n",
    "            # Compute the PLSRW weight\n",
    "            w_inter = pinv2(\n",
    "                ((Xk.T @ Xk) + (reg * (D.T @ D))), check_finite=False)\n",
    "            x_weights = (w_inter @ Xk.T) @ Yk\n",
    "            print(\"x_weights:\", x_weights.shape)\n",
    "            \n",
    "            # Normalize weight\n",
    "            x_weights /= np.sqrt(x_weights.T @ x_weights) + eps\n",
    "            \n",
    "            # Calculate the corresponding scores and loadings\n",
    "            x_scores = Xk @ x_weights\n",
    "            x_loadings = (Xk.T @ x_scores) / (x_scores.T @ x_scores)\n",
    "            y_loadings = (Yk.T @ x_scores) / (x_scores.T @ x_scores)\n",
    "            \n",
    "            # Deflate X and Y\n",
    "            Xk -= np.outer(x_scores, x_loadings)\n",
    "            Yk -= np.outer(x_scores, y_loadings)\n",
    "            print(\"Xk:\", Xk.shape, \"Yk:\", Yk.shape)\n",
    "            \n",
    "            self.x_weights_[:, k] = x_weights[:, 0]\n",
    "            self._x_scores[:, k] = x_scores[:, 0]\n",
    "            self.x_loadings_[:, k] = x_loadings[:, 0]\n",
    "            self.y_loadings_[:, k] = y_loadings[:, 0]\n",
    "\n",
    "        # Compute transformation matrices\n",
    "        self.x_rotations_ = np.dot(\n",
    "            self.x_weights_,\n",
    "            pinv2(np.dot(self.x_loadings_.T, self.x_weights_),\n",
    "                  check_finite=False))\n",
    "        \n",
    "        self.coef_ = np.dot(self.x_rotations_, self.y_loadings_.T)\n",
    "        self.coef_ = self.coef_ * self._y_std\n",
    "        print(\"coef:\", self.coef_.shape)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.coef_\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plsrw = PLSRW(n_components=2, reg=0)\n",
    "plsrw.fit(X, y)\n",
    "print(plsrw.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS Group-and-Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def group_and_average(X, y, group_size=3):\n",
    "    X_temp, y_temp = [], []\n",
    "    \n",
    "    # Multiply by 2 to enable the splits to be random\n",
    "    num_sections = X.shape[0] / (group_size * 2)\n",
    "    X_indices = np.arange(X.shape[0])\n",
    "    subarray_indices = np.array(np.split(X_indices, num_sections, axis=0))\n",
    "    \n",
    "    # Shuffle each section so each time the split is run, the groups are different\n",
    "    rng = np.random.default_rng()\n",
    "    rng.shuffle(subarray_indices, axis=1)\n",
    "    \n",
    "    for subarray in subarray_indices:\n",
    "        # Half each section to return to the original group size\n",
    "        front_half, back_half = subarray[:group_size], subarray[group_size:]\n",
    "        X_temp.append(np.mean(X[front_half], axis=0))\n",
    "        X_temp.append(np.mean(X[back_half], axis=0))\n",
    "        \n",
    "        y_temp.append(np.mean(y[front_half]))\n",
    "        y_temp.append(np.mean(y[back_half]))\n",
    "    \n",
    "    X_temp, y_temp = shuffle(X_temp, y_temp)\n",
    "    return np.array(X_temp), np.array(y_temp)\n",
    "\n",
    "\n",
    "def group_and_average_by_y(X, y, group_size=3):\n",
    "    # Sort data by target\n",
    "    sort_indices = np.argsort(y)\n",
    "    X, y = X[sort_indices], y[sort_indices]\n",
    "    \n",
    "    return group_and_average(X, y, group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "num_component = 2\n",
    "train_scores, test_scores = [], []\n",
    "pearsonr_scores, spearmanr_scores = [], []\n",
    "coefs = []\n",
    "\n",
    "for j in range(0, 10):\n",
    "    X_group, y_group = group_and_average_by_y(X, y)\n",
    "    mi = SelectKBest(mutual_info_regression, k=3000)\n",
    "    X_group = mi.fit_transform(X_group, y_group)\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_group, y_group, test_size=0.3, shuffle=True)\n",
    "\n",
    "        pls = PLSRegression(n_components=num_component)\n",
    "        pls.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = pls.predict(X_train)\n",
    "        y_test_pred = pls.predict(X_test)[:, 0]\n",
    "\n",
    "        train_scores.append(r2_score(y_train, y_train_pred))\n",
    "        test_scores.append(r2_score(y_test, y_test_pred))\n",
    "        pearsonr_scores.append(stats.pearsonr(y_test, y_test_pred)[0])\n",
    "        spearmanr_scores.append(stats.spearmanr(y_test, y_test_pred)[0])\n",
    "        coefs.append(pls.coef_)\n",
    "\n",
    "avg_train_score, avg_test_score = np.mean(train_scores), np.mean(test_scores)\n",
    "avg_pearsonr, avg_spearmanr = np.mean(pearsonr_scores), np.mean(spearmanr_scores)\n",
    "avg_coef = np.mean(coefs, axis=0)\n",
    "\n",
    "print(f'Measure: {selected_measure}')\n",
    "print(f\"Avg train score: {avg_train_score:.3f}\")\n",
    "print(f\"Avg test score: {avg_test_score:.3f}\")\n",
    "print(f\"Avg pearson: {avg_pearsonr:.3f}\")\n",
    "print(f\"Avg spearman: {avg_spearmanr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS Iteration with Percentage Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "num_component = 2\n",
    "train_scores, test_scores = [], []\n",
    "pearsonr_scores, spearmanr_scores = [], []\n",
    "coefs = []\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, shuffle=True)\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_train_pred = pipe.predict(X_train)\n",
    "    y_test_pred = pipe.predict(X_test)[:, 0]\n",
    "    \n",
    "    train_scores.append(r2_score(y_train, y_train_pred))\n",
    "    test_scores.append(r2_score(y_test, y_test_pred))\n",
    "    pearsonr_scores.append(stats.pearsonr(y_test, y_test_pred)[0])\n",
    "    spearmanr_scores.append(stats.spearmanr(y_test, y_test_pred)[0])\n",
    "    coefs.append(pls.coef_)\n",
    "    \n",
    "    if (i == 0):\n",
    "        print(X_train.shape, X_test.shape)\n",
    "\n",
    "avg_train_score, avg_test_score = np.mean(train_scores), np.mean(test_scores)\n",
    "avg_pearsonr, avg_spearmanr = np.mean(pearsonr_scores), np.mean(spearmanr_scores)\n",
    "avg_coef = np.mean(coefs, axis=0)\n",
    "\n",
    "print(f\"Avg train score: {avg_train_score:.4f}\")\n",
    "print(f\"Avg test score: {avg_test_score:.4f}\")\n",
    "print(f\"Avg pearson: {avg_pearsonr:.4f}\")\n",
    "print(f\"Avg spearman: {avg_spearmanr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded PLS Regression using K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rkf = RepeatedKFold(n_splits=10, n_repeats=1, random_state=251183)\n",
    "train_scores, test_scores = [], []\n",
    "pearsonr_scores, spearmanr_scores = [], []\n",
    "coefs = []\n",
    "\n",
    "for train_index, test_index in rkf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), PLSRegression(n_components=2))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_train_pred = pipe.predict(X_train)\n",
    "    y_test_pred = pipe.predict(X_test)[:, 0]\n",
    "    \n",
    "    train_scores.append(r2_score(y_train, y_train_pred))\n",
    "    test_scores.append(r2_score(y_test, y_test_pred))\n",
    "    pearsonr_scores.append(stats.pearsonr(y_test, y_test_pred)[0])\n",
    "    spearmanr_scores.append(stats.spearmanr(y_test, y_test_pred)[0])\n",
    "    coefs.append(pipe['plsregression'].coef_)\n",
    "\n",
    "avg_train_score, avg_test_score = np.mean(train_scores), np.mean(test_scores)\n",
    "avg_pearsonr, avg_spearmanr = np.mean(pearsonr_scores), np.mean(spearmanr_scores)\n",
    "avg_coef = np.mean(coefs, axis=0)\n",
    "\n",
    "print(f'Measure: {selected_target}')\n",
    "print(f\"Avg train score: {avg_train_score:.2f}\")\n",
    "print(f\"Avg test score: {avg_test_score:.2f}\")\n",
    "print(f\"Avg pearson: {avg_pearsonr:.2f}\")\n",
    "print(f\"Avg spearman: {avg_spearmanr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQ Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bins = bin_by_feature(X, y, y, 3)\n",
    "bin_1, bin_2, bin_3 = bins[0], bins[1], bins[2]\n",
    "print(f'Bin 1: {bin_1[0].shape} | Bin 2: {bin_2[0].shape} | Bin 3: {bin_3[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_noise_samples(X, y, num_times):\n",
    "    X_std = np.std(X, axis=0)\n",
    "    \n",
    "    for i in range(0, num_times):\n",
    "        X_noisy = X + np.random.normal(0, X_std, X.shape)\n",
    "        X, y = np.append(X, X_noisy, axis=0), np.append(y, y)\n",
    "    \n",
    "    return shuffle(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display PLS plots during or after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "# fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "# x_fig, y_fig = 0, 0\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3)\n",
    "    \n",
    "    pls = PLSRegression(n_components=num_component)\n",
    "    pls.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pls.predict(X_train)\n",
    "    y_test_pred = pls.predict(X_test)\n",
    "    \n",
    "    train_scores.append(r2_score(y_train, y_train_pred))\n",
    "    test_scores.append(r2_score(y_test, y_test_pred))\n",
    "    \n",
    "#     if (i % 10 == 0):\n",
    "#         axs[y_fig, x_fig].scatter(y_test, y_test_pred, alpha=0.3)\n",
    "#         m, b, r, p, std_err = stats.linregress(y_test, y_test_pred[:,0])\n",
    "#         axs[y_fig, x_fig].plot(y_test, (m * y_test) + b, alpha=0.3)\n",
    "#         print(x_fig, y_fig, f\"r:{r:.2f}\", f\"r^2:{test_scores[-1]:.2f}\")\n",
    "#         x_fig += 1\n",
    "#         if (x_fig % 3 == 0):\n",
    "#             x_fig = 0\n",
    "#             y_fig += 1\n",
    "\n",
    "avg_train_score = np.mean(train_scores)\n",
    "avg_test_score = np.mean(test_scores)\n",
    "\n",
    "print(\"Train r^2:\", avg_train_score)\n",
    "print(\"Test r^2:\", avg_test_score)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "lin_reg_train = LinearRegression().fit(y_train, y_train_pred)\n",
    "y_train_pred_lin_reg = lin_reg_train.predict(y_train)\n",
    "\n",
    "lin_reg_test = LinearRegression().fit(y_test, y_test_pred)\n",
    "y_test_pred_lin_reg = lin_reg_test.predict(y_test)\n",
    "\n",
    "lin_reg_train_score = lin_reg_train.score(y_train, y_train_pred)\n",
    "lin_reg_test_score = lin_reg_test.score(y_test, y_test_pred)\n",
    "print(\"Train r^2:\", lin_reg_train_score)\n",
    "print(\"Test r^2:\", lin_reg_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_true = y_test.reshape(-1, 1)\n",
    "y_pred = y_test_pred.reshape(-1, 1)\n",
    "\n",
    "lr = LinearRegression().fit(y_true, y_pred)\n",
    "lr_pred = lr.predict(y_true)\n",
    "print(r2_score(y_true, y_pred), r2_score(y_true, lr_pred))\n",
    "\n",
    "plt.scatter(y_true, y_pred, alpha=0.3)\n",
    "plt.plot(y_true, lr_pred)\n",
    "plt.title(\"Training Set\")\n",
    "plt.xlabel(f'True {selected_target}')\n",
    "plt.ylabel(f'Predicted {selected_target}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_train, y_train_pred, alpha=0.3, color='black')\n",
    "plt.plot(y_train, y_train_pred_lin_reg, color='#897B61')\n",
    "plt.title(\"Training Set\")\n",
    "plt.xlabel(f'True {selected_measure}')\n",
    "plt.ylabel(f'Predicted {selected_measure}')\n",
    "# plt.annotate(f\"r-squared = {avg_train_score:.3f}\", (6, 16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_test_pred, alpha=0.3, color='black')\n",
    "plt.plot(y_test, y_test_pred_lin_reg, color='#897B61')\n",
    "plt.title(\"Testing Set\")\n",
    "plt.xlabel(f'True {selected_measure}')\n",
    "plt.ylabel(f'Predicted {selected_measure}')\n",
    "# plt.annotate(f\"r-squared = {lin_reg_test_score:.2f}\", (60, 87))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10, 10))\n",
    "plt.hist(x=test_scores, rwidth=0.95)\n",
    "plt.title(\"Test Score Distribution\")\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Yeo FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# To display each class of connections (within and between)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(subject_fc)\n",
    "a = np.zeros((11, 11))\n",
    "a[fpn_indices] = subject_fc[fpn_indices]\n",
    "plt.imshow(a)\n",
    "b = np.zeros((8, 8))\n",
    "b[np.triu_indices(8, k=1)] = subject_fc[dmn_indices]\n",
    "plt.imshow(b)\n",
    "plt.imshow(subject_fc[:11, 11:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Brain Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For plotting other functional images\n",
    "img = image.load_img(f'{subject_path}/wr{subject}_task-movieDM_bold_0375.nii')\n",
    "concat_img = image.concat_imgs(subject_niftis)\n",
    "img = image.index_img(concat_img, 0)\n",
    "img = image.mean_img(concat_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (Poor Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(0.055)\n",
    "X = sel.fit_transform(X)\n",
    "print(\"X shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select k strongest connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def score_fc(X, y):\n",
    "    # Take the strongest correlations regardless of sign\n",
    "    sum_fc = np.absolute(np.sum(X, axis=0))\n",
    "    return sum_fc\n",
    "\n",
    "X = SelectKBest(score_fc, k=3400).fit_transform(X, y)\n",
    "print(\"X shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display MI Before and After Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mi = SelectKBest(mutual_info_regression, k=1000)\n",
    "X_mi = mi.fit_transform(X, y)\n",
    "print(\"X_mi shape:\", X_mi.shape)\n",
    "\n",
    "mi_bin_1 = SelectKBest(mutual_info_regression, k=3000)\n",
    "X_bin_1 = mi_bin_1.fit_transform(bin_1[0], bin_1[1])\n",
    "\n",
    "mi_bin_2 = SelectKBest(mutual_info_regression, k=2000)\n",
    "X_bin_2 = mi_bin_2.fit_transform(bin_2[0], bin_2[1])\n",
    "\n",
    "mi_bin_3 = SelectKBest(mutual_info_regression, k=500)\n",
    "X_bin_3 = mi_bin_3.fit_transform(bin_3[0], bin_3[1])\n",
    "\n",
    "print(f'X_bin_1: {X_bin_1.shape} | X_bin_2: {X_bin_2.shape} | X_bin_3: {X_bin_3.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.plotting import create_power_fc_matrix, plot_fc_matrix, plot_fc_graph\n",
    "\n",
    "plot_fc_matrix(create_power_fc_matrix(X[1]), -1, 1)\n",
    "plot_fc_matrix(create_power_fc_matrix(mi.inverse_transform(X_1[1].reshape(1, -1))), -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Diagnosis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_measures = ['Age', 'Sex', 'Diagnosis']\n",
    "\n",
    "if measure == 'Diagnosis':\n",
    "    demographics[measure].append(\n",
    "        wisc_labels.at[subject_id, f'assessment Diagnosis_ClinicianConsensus,NoDX'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
